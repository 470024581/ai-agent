#!/usr/bin/env python3
"""
OpenRouter æ¨¡å‹é…ç½®å·¥å…·
"""

# å¯ç”¨çš„OpenRouteræ¨¡å‹
AVAILABLE_MODELS = {
    "å…è´¹æ¨¡å‹": {
        "meta-llama/llama-3-8b-instruct:free": "Llama 3 8B - å…è´¹",
        "microsoft/phi-3-mini-128k-instruct:free": "Phi-3 Mini - å…è´¹",
        "google/gemma-7b-it:free": "Gemma 7B - å…è´¹",
    },
    "ç»æµå‹æ¨¡å‹": {
        "anthropic/claude-3-haiku:beta": "Claude 3 Haiku - å¿«é€Ÿç»æµ",
        "openai/gpt-3.5-turbo": "GPT-3.5 Turbo - ç»å…¸é€‰æ‹©",
        "google/gemini-flash-1.5": "Gemini Flash - å¿«é€Ÿå“åº”",
    },
    "é«˜æ€§èƒ½æ¨¡å‹": {
        "anthropic/claude-3-sonnet:beta": "Claude 3 Sonnet - å¹³è¡¡æ€§èƒ½",
        "openai/gpt-4-turbo": "GPT-4 Turbo - å¼ºå¤§æ™ºèƒ½",
        "google/gemini-pro-1.5": "Gemini Pro - è°·æ­Œæ——èˆ°",
    }
}

def list_models():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
    print("ğŸ¤– OpenRouter å¯ç”¨æ¨¡å‹:")
    print("=" * 50)
    
    for category, models in AVAILABLE_MODELS.items():
        print(f"\nğŸ“‚ {category}:")
        for model_id, description in models.items():
            print(f"   â€¢ {model_id}")
            print(f"     {description}")

def switch_model(model_id: str, config_path: str = '../config/config.py'): # Adjusted path
    """åˆ‡æ¢åˆ°æŒ‡å®šæ¨¡å‹"""
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨åˆ—è¡¨ä¸­
        all_models = {}
        for category in AVAILABLE_MODELS.values():
            all_models.update(category)
        
        if model_id not in all_models:
            print(f"âŒ æ¨¡å‹ '{model_id}' ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­")
            print("ğŸ’¡ ä½¿ç”¨ python app/openrouter_models.py list æŸ¥çœ‹å¯ç”¨æ¨¡å‹") # Adjusted help path
            return False
        
        # è¯»å–å½“å‰é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ›´æ–°æ¨¡å‹é…ç½®
        import re
        # æ‰¾åˆ°OPENAI_MODELè¡Œå¹¶æ›¿æ¢
        pattern = r'OPENAI_MODEL = "[^"]*"'
        new_line = f'OPENAI_MODEL = "{model_id}"'
        
        if re.search(pattern, content):
            new_content = re.sub(pattern, new_line, content)
        else:
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œæ·»åŠ åˆ°æ–‡ä»¶æœ«å°¾
            new_content = content.rstrip() + f'\nOPENAI_MODEL = "{model_id}"\n' # Ensure newline
        
        # å†™å›æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print(f"âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹: {model_id}")
        print(f"ğŸ“ æè¿°: {all_models[model_id]}")
        print("\nğŸ”„ è¯·é‡å¯æœåŠ¡å™¨ä½¿é…ç½®ç”Ÿæ•ˆ:")
        print("   (cd .. && uvicorn app.main:app --reload --port 8001)  # If running from app dir")
        print("   (uvicorn app.main:app --reload --port 8001)           # If running from root dir")
        
        return True
        
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        print("ç¡®ä¿ config/config.py æ–‡ä»¶å­˜åœ¨")
        return False
    except Exception as e:
        print(f"âŒ åˆ‡æ¢å¤±è´¥: {e}")
        return False

def test_model(config_path: str = '../config/config.py'): # Adjusted path
    """æµ‹è¯•å½“å‰æ¨¡å‹"""
    print("ğŸ§ª æµ‹è¯• OpenRouter è¿æ¥...")
    
    try:
        # Dynamically import config based on path
        import importlib.util
        spec = importlib.util.spec_from_file_location("config_module", config_path)
        config_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(config_module)
        
        from langchain_openai import ChatOpenAI
        
        llm_kwargs = {
            "model_name": config_module.OPENAI_MODEL,
            "temperature": 0.3,
            "openai_api_key": config_module.OPENAI_API_KEY
        }
        
        if hasattr(config_module, 'OPENAI_BASE_URL') and config_module.OPENAI_BASE_URL:
            llm_kwargs["openai_api_base"] = config_module.OPENAI_BASE_URL
        
        llm = ChatOpenAI(**llm_kwargs)
        
        # æµ‹è¯•ç®€å•æŸ¥è¯¢
        response = llm.invoke("Hello! Please respond with 'OpenRouter connection successful.'")
        
        print("âœ… è¿æ¥æˆåŠŸ!")
        print(f"ğŸ“ æ¨¡å‹: {config_module.OPENAI_MODEL}")
        print(f"ğŸ’¬ å“åº”: {response.content}")
        
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
    except AttributeError as e:
        print(f"âŒ é…ç½®é”™è¯¯: {e} - è¯·ç¡®ä¿ OPENAI_MODEL å’Œ OPENAI_API_KEY åœ¨ config.py ä¸­å®šä¹‰")
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥API Keyå’Œç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    import sys
    import os

    # Determine the correct config path based on execution context
    # This script is now in app/, so config is in ../config/
    current_dir = os.path.dirname(os.path.abspath(__file__))
    config_file_path = os.path.join(current_dir, '..', 'config', 'config.py')
    
    if len(sys.argv) < 2:
        print("OpenRouter æ¨¡å‹é…ç½®å·¥å…· (ä½äº app/ ç›®å½•)")
        print("\nä½¿ç”¨æ–¹æ³• (ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ):")
        print("  python app/openrouter_models.py list                    # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹")
        print("  python app/openrouter_models.py switch <model_id>       # åˆ‡æ¢æ¨¡å‹")
        print("  python app/openrouter_models.py test                    # æµ‹è¯•è¿æ¥")
        print("\nç¤ºä¾‹:")
        print("  python app/openrouter_models.py switch anthropic/claude-3-haiku:beta")
    
    elif sys.argv[1] == "list":
        list_models()
    elif sys.argv[1] == "switch" and len(sys.argv) > 2:
        switch_model(sys.argv[2], config_path=config_file_path)
    elif sys.argv[1] == "test":
        test_model(config_path=config_file_path)
    else:
        print("âŒ æ— æ•ˆå‘½ä»¤")
        print("ä½¿ç”¨ python app/openrouter_models.py æŸ¥çœ‹å¸®åŠ©") 