# üê≥ AI Agent Docker Deployment

## Quick Start

### Prerequisites
- Docker installed
- Docker Compose installed
- OpenAI API key

### Deployment Steps

#### 1. Clone and Configure
```bash
git clone <your-repository-url>
cd ai-agent

# Copy environment template
cp docker.env.example .env

# Edit .env file and set your OpenAI API key
nano .env
```

#### 2. Deploy with Script (Recommended)
```bash
chmod +x docker-deploy.sh
./docker-deploy.sh
```

#### 3. Manual Deployment
```bash
# Create data directories
mkdir -p docker_data/{app_data,embeddings_cache}

# Build and start
docker compose build ai-agent
docker compose up -d ai-agent
```

### Access Application
- **Application**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

### Configuration

#### Required Environment Variables
```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-3.5-turbo

# Basic Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false
```

### Management Commands

```bash
# View service status
docker compose ps

# View logs
docker compose logs -f ai-agent

# Restart service
docker compose restart ai-agent

# Stop service
docker compose down

# Rebuild service
docker compose build --no-cache ai-agent
```

### Data Persistence

Application data is stored in:
- `./docker_data/app_data` - Database and uploaded files
- `./docker_data/embeddings_cache` - Embedding model cache

### Troubleshooting

1. **Service fails to start**
   ```bash
   docker compose logs ai-agent
   ```

2. **Port conflicts**
   ```bash
   # Change port in docker-compose.yml
   ports:
     - "8080:8000"  # Use port 8080 instead
   ```

3. **Permission issues**
   ```bash
   chmod -R 755 docker_data/
   ```

### Security Notes

For production deployment:
- Change `SECRET_KEY` in `.env`
- Use HTTPS proxy (nginx, traefik)
- Restrict CORS origins
- Use proper firewall rules

---

‚úÖ **Your AI Agent application is now running in Docker with OpenAI integration!** 